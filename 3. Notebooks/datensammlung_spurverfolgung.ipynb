{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spurverfolgung - Datensammlung\n",
    "\n",
    "Auch hier werden wieder die folgenden Schritte durchgeführt:\n",
    "\n",
    "1.  Datensammlung\n",
    "2.  Training\n",
    "3.  Live-Einsatz\n",
    "\n",
    "Im Unterschied zu der vorherigen Fähigkeit wird hier nicht mehr die Klassifizierung eingesetzt, sondern die **Regression**. Diese wird verwendet um dem Jetbot zu ermöglichen eine Spur zu verfolgen (bzw. einen beliebigen Pfad oder Zielpunkt).\n",
    "\n",
    "1. Sammeln von Daten für verschiedene Positionen des Jetbots auf dem Pfad (verschiedene Abstände zum Mittelpunkt, verschiedene Winkel, etc.)\n",
    "\n",
    ">  Wie auch schon bei der Kollisionsvermeidung gilt: Datenvarianz ist entscheident!\n",
    "\n",
    "2. Live-Bild der Kamera anzeigen\n",
    "3. 'Grünen Punkt', welcher der Zielrichtung des Roboters entspricht, auf dem Bild platzieren\n",
    "4. X und Y Werte des grünen Punktes zusammen mit dem Bild der Kamera des Roboters speichern\n",
    "\n",
    "Dannach wird im Trainings-Notebook ein neuronales Netztwerk trainiert, welches die X und Y Werte des Labels vorhersagen kann. Im Live-Demo-Notebook werden die X und Y Werte verwendet um einen ungefähren Steuerwert zu berechnen.\n",
    "\n",
    "Wie wird der Zielpunkt richtig platziert?\n",
    "\n",
    "1.  Auf das Livebild der Kamera gucken\n",
    "2.  Überlegen welchen Pfad der Roboter auf dem Bild fahren sollte (Entfernung abschätzen, nach der der Roboter von der Straße abkommen würde)\n",
    "3.  Zielpunkt so weit wie möglich in die Ferne platzieren, so dass der Roboter möglichst lange geradeaus fahren kann, bevor er von der Straße abkommt.\n",
    "\n",
    "> Beispiel: Bleibt die Strecke lange gerade, kann der Zielpunkt weit in die Ferne gesetzt werden. Liegt eine scharfe Kurve bevor, muss der Zielpunkt nah am Roboter platziert werden, da er sonst nicht mehr die Spur halten würde.\n",
    "\n",
    "Tut das nueronale Netzt das was ihm angelernt wurde, versichern die Label-Richtlinien folgendes:\n",
    "\n",
    "1.  Der Roboter kann sicher in Richting eines Ziels fahren (ohne dabei von der Straße abzukommen)\n",
    "2.  Der Zielpunkt bewegt sich immer weiter entlang der zu fahrenden Strecke\n",
    "\n",
    "Man kann sich das Ergebnis so ähnlich vorstellen wie das Reiten eines Esels mit einer Karotte an einer Angel. Der wesentliche Unterschied ist, dass das neuronale Netzt vorgibt, wo sich die Karotte befindet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einbinden der Bibliotheken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Von entscheidender Rolle ist hier die Bibliothek OpenCV mit der die Kamerabilder sowohl dargestellt als auch mit Labeln angespeichert werden können. Bibliotheken wie uuid und datetime werden für die Namensgebung der Bilddateien verwendet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IPython Libraries for display and widgets\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Camera and Motor Interface for JetBot\n",
    "from jetbot import Robot, Camera, bgr8_to_jpeg\n",
    "\n",
    "# Basic Python packages for image annotation\n",
    "from uuid import uuid1\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import datetime\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datensammlung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Erneut soll das Kamerabild wieder angezeigt werden. Diesmal wird jedoch ein spezielles ipywidget verwendet (`jupyter_clickable_image_widget`), welches es ermöglicht auf das Bild zu klicken und die Koordinaten des Labels zu speichern.\n",
    "\n",
    "Es wird die Kamera Klasse des Jetbot verwendet, um die CSI MIPI Kamera zu aktivieren. Das neuronale Netzwerk nimmt ein Bild mit den Maßen 224x224 Pixel als Eingabe entgegen. Die Kamera wird auf diese Größe gesetzt, um die Dateigröße des Datensatzes zu minimieren. In einigen Szenarien kann es besser sein, Daten in einer größeren Bildgröße zu sammeln und später auf die gewünschte Größe zu skalieren. \n",
    "\n",
    "Der folgende Codeblock zeigt das Livebild der Kamera auf welches geklickt werden kann, um ein Label zu platzieren. Daneben wird das letzte Bild angezeigt, auf welchem ein grüner Kreis zu sehen ist, wo zuvor geklickt wurde. Darunter wird die Anzahl der gespeicherten Bilder angezeigt.  \n",
    "\n",
    "Wird links auf das Livebild geklickt, dann wird ein Bild inklusive Label im ``dataset_xy`` abgespeichert mit dem Namen\n",
    "\n",
    "``xy_<x value>_<y value>_<uuid>.jpg``\n",
    "\n",
    "Beim TRainieren werden die Bilder geladen und die X und Y Werte aus dem Dateinamen extrahiert.\n",
    "\n",
    "Dabei sind `<x value>` und `<y value>` die Koordinaten **in Pixeln** (gezählt von der linken oberen Ecke)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jupyter_clickable_image_widget import ClickableImageWidget\n",
    "\n",
    "DATASET_DIR = 'dataset_xy'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(DATASET_DIR)\n",
    "except FileExistsError:\n",
    "    print('Directories not created because they already exist')\n",
    "\n",
    "camera = Camera()\n",
    "\n",
    "# create image preview\n",
    "camera_widget = ClickableImageWidget(width=camera.width, height=camera.height)\n",
    "snapshot_widget = ipywidgets.Image(width=camera.width, height=camera.height)\n",
    "traitlets.dlink((camera, 'value'), (camera_widget, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "# create widgets\n",
    "count_widget = ipywidgets.IntText(description='count')\n",
    "# manually update counts at initialization\n",
    "count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "\n",
    "def save_snapshot(_, content, msg):\n",
    "    if content['event'] == 'click':\n",
    "        data = content['eventData']\n",
    "        x = data['offsetX']\n",
    "        y = data['offsetY']\n",
    "        \n",
    "        # save to disk\n",
    "        #dataset.save_entry(category_widget.value, camera.value, x, y)\n",
    "        uuid = 'xy_%03d_%03d_%s' % (x, y, uuid1())\n",
    "        image_path = os.path.join(DATASET_DIR, uuid + '.jpg')\n",
    "        with open(image_path, 'wb') as f:\n",
    "            f.write(camera_widget.value)\n",
    "        \n",
    "        # display saved snapshot\n",
    "        snapshot = camera.value.copy()\n",
    "        snapshot = cv2.circle(snapshot, (x, y), 8, (0, 255, 0), 3)\n",
    "        snapshot_widget.value = bgr8_to_jpeg(snapshot)\n",
    "        count_widget.value = len(glob.glob(os.path.join(DATASET_DIR, '*.jpg')))\n",
    "        \n",
    "camera_widget.on_msg(save_snapshot)\n",
    "\n",
    "data_collection_widget = ipywidgets.VBox([\n",
    "    ipywidgets.HBox([camera_widget, snapshot_widget]),\n",
    "    count_widget\n",
    "])\n",
    "\n",
    "display(data_collection_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie bereits in anderen Notebooks muss am Ende wieder die Kamera freigegeben werden (Verbindung trennen)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Auch hier gilt wieder: Wurden genügend Daten gesammelt, so können diese wieder zum Trainieren auf einen Leistungsstarken Computer übertragen werden.  \n",
    "\n",
    "> Sollte der Wunsch bestehen das Trainieren auf dem Jetbot selbst durchzuführen, so kann dieser Schritt übersprungen werden. Es sollte sich jedoch auf eine lange Berechnungszeit eingestellt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der folgende Codeblock komprimiert die Bilddaten wieder in eine zip Datei, welche dann auf einen Leistungsstarken Computer übertragen werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestr():\n",
    "    return str(datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S'))\n",
    "\n",
    "!zip -r -q road_following_{DATASET_DIR}_{timestr()}.zip {DATASET_DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es sollte nun eine Datei angelegt worden sein mit dem Namen road_following_<Date&Time>.zip. Diese kann heruntergeladen werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
