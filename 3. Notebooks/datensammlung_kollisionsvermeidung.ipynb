{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kollisionsvermeidung - Datensammlung\n",
    "\n",
    "Im nächsten Schritt soll es darum gehen den Jetbot von selbst fahren zu lassen. \n",
    "\n",
    "Dabei handelt es sich um eine schwierige Aufgabe, die jedoch in kleinere Teilaufgaben unterteilt werden kann. Eine der wichtigsten Aufgaben bzw. Fähigkeiten, die der Roboter besitzen muss ist,\n",
    "dass er sich nicht selbst in gefährliche Situationen begeben kann. Diese Fähigkeit wird nachfolgend als *Kollisionsvermeidung* bezeichnet. \n",
    "\n",
    "Die folgenden Notebooks beschäftigen sich mit der Umsetzung dieser Fähigkeit mithilfe von Neuronalen Netzen und der Kamera des Roboters als Sensor.\n",
    "\n",
    "Der Ansatz ist dabei eine virtualle \"safety bubble\" um den Roboter herum zu erstellen. Innerhalb dieser Blase kann dieser sich frei im Kreis drehen, ohne dass er mit Hindernissen kollidiert oder von einem Vorsprung herunterfällt.  \n",
    "\n",
    "\n",
    "Konkret würd dafür wie folgt vorgegangen:  \n",
    "\n",
    "Als erstes wird der Jetbot in Szenarien platziert, wo seine \"safety bubble\" verletzt wird. Dazu werden Bilder aufgenommen zusammen mit dem Label ``blocked``.\n",
    "\n",
    "Als zweites wird er in Szenarien platziert, wo er sich nach vorne bewegen könnte, ohne dass er mit etwas Kollidiert. Es werden ebenfalls Bilder aufgenommen, diesmal jedoch mit dem Label ``free``.\n",
    "\n",
    "Nachdem genügend gelabelte Bilder aufgenommen wurden (ca. 100 sollten fürs erste genügen), werden diese auf einen Computer mit einer schnellen GPU geladen, um dort das neuronale Netzwerk zu *trainieren*, so dass es anhand der aufgenommenen Bilder entscheiden kann, ob die safety bubble des Jetbots verletzt wurde. Damit wird es möglich sein am Ende die Fähigkeit der Kollisionsvermeidung zu implementieren."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live-Bild der Kamera anzeigen\n",
    "\n",
    "Zunächst wird die Kamera initialisiert und ihr Bild angezeigt.  \n",
    "\n",
    "> Das neuronale Netzwerk erwartet Bilder mit der Auflösung von 224x224 Pixeln als Eingabe.  Dafür wird die Auflösung der Kamera entsprechend dieser Anforderung gesetzt, was ebenfalls dafür sorgt, dass die Dateigröße minimiert wird.\n",
    "> Es gibt grundsätzlich auch Szenarien, wo es von Vorteil wäre die volle Auflösung zu nutzen und erst zu einen späteren Zeitpunkt die Bilder zu komprimieren. Dies wird hier jedoch nicht behandelt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import traitlets\n",
    "import ipywidgets.widgets as widgets\n",
    "from IPython.display import display\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera.instance(width=224, height=224)\n",
    "\n",
    "image = widgets.Image(format='jpeg', width=224, height=224)  # this width and height doesn't necessarily have to match the camera\n",
    "\n",
    "camera_link = traitlets.dlink((camera, 'value'), (image, 'value'), transform=bgr8_to_jpeg)\n",
    "\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächsten werden Verzeichnisse angelegt, in denen die Bild-Daten gespeichert werden. Es wird ein Verzeichnis ``dataset`` angelegt, welches zwei Unterordner ``free`` und ``blocked`` enthält. In diesen werden die Bilder für die jeweiligen Szenarien gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "blocked_dir = 'dataset/blocked'\n",
    "free_dir = 'dataset/free'\n",
    "\n",
    "# we have this \"try/except\" statement because these next functions can throw an error if the directories exist already\n",
    "try:\n",
    "    os.makedirs(free_dir)\n",
    "    os.makedirs(blocked_dir)\n",
    "except FileExistsError:\n",
    "    print('Directories not created because they already exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als nächstest werden Buttons angelegt, mit denen die Bilder mitsamt Label gespeichert werden können. Außerdem werden Textfelder angelegt, die anzeigen, wie viele Bilder für die jeweiligen Kategorien bereits gespeichert wurden. Dies ist hilfreich, um sicherzustellen, dass etwa gleich viele Bilder für die Kategorien ``free`` und ``blocked`` gespeichert wurden. Außerdem hilft es zu wissen, wie viele Bilder insgesamt gespeichert wurden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "button_layout = widgets.Layout(width='128px', height='64px')\n",
    "free_button = widgets.Button(description='add free', button_style='success', layout=button_layout)\n",
    "blocked_button = widgets.Button(description='add blocked', button_style='danger', layout=button_layout)\n",
    "free_count = widgets.IntText(layout=button_layout, value=len(os.listdir(free_dir)))\n",
    "blocked_count = widgets.IntText(layout=button_layout, value=len(os.listdir(blocked_dir)))\n",
    "\n",
    "display(widgets.HBox([free_count, free_button]))\n",
    "display(widgets.HBox([blocked_count, blocked_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aktuell haben die Buttons noch keine Funktion. Dafür müssen die Funktionen zum speichern der Bilder der jeweiligen Kategorie erst mit dem ``on_click`` Event der Buttons verbunden werden. Die Bilder werden dabei aus dem ``Image`` Widget gespeichert, da diese bereits im komprimierten JPEG Format vorliegen.\n",
    "\n",
    "Um sicherzugehen, dass keine Dateinamen doppelt vergeben werden (auch nicht auf verschiedenen Computern), wird das ``uuid`` Paket in Python verwendet, welches die ``uuid1`` Methode definiert, um einen eindeutigen Identifikator zu generieren. Dieser eindeutige Identifikator wird aus Informationen wie der aktuellen Zeit und der Maschinenadresse generiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid1\n",
    "\n",
    "def save_snapshot(directory):\n",
    "    image_path = os.path.join(directory, str(uuid1()) + '.jpg')\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(image.value)\n",
    "\n",
    "def save_free():\n",
    "    global free_dir, free_count\n",
    "    save_snapshot(free_dir)\n",
    "    free_count.value = len(os.listdir(free_dir))\n",
    "    \n",
    "def save_blocked():\n",
    "    global blocked_dir, blocked_count\n",
    "    save_snapshot(blocked_dir)\n",
    "    blocked_count.value = len(os.listdir(blocked_dir))\n",
    "    \n",
    "# attach the callbacks, we use a 'lambda' function to ignore the\n",
    "# parameter that the on_click event would provide to our function\n",
    "# because we don't need it.\n",
    "free_button.on_click(lambda x: save_free())\n",
    "blocked_button.on_click(lambda x: save_blocked())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun können die Buttons Bilder in den ``free`` und ``blocked`` Ordnern abspeichern.\n",
    "\n",
    "Als nächstes kann mit dem Aufnehmen von Bildern begonnen werden: \n",
    "\n",
    "1. Jetbot in einem Szenario platzieren, wo er blockiert ist und ``add blocked`` drücken\n",
    "2. Roboter in einem Szenario platzieren, wo er frei ist und den Button ``add free`` betätigen\n",
    "3. 1 und 2 wiederholen, bis genügend Bilder gespeichert wurden\n",
    "\n",
    "Tipps für das Labeln der Daten:\n",
    "\n",
    "1. Verschiedene Ausrichtungen des Roboters aufnehmen\n",
    "2. Verschiedene Lichtverhältnisse aufnehmen\n",
    "3. Verschiedene Typen von Kollisionen aufnehmen (z.B. Wände, Vorsprünge, Gegenstände)\n",
    "4. Verschiedene Texturen aufnehmen (z.B. glatte Oberflächen, rauhe Oberflächen, etc.)\n",
    "\n",
    "Grundsätzlich kann gesagt werden, um so mehr Daten aufgenommen wurden für verschiedene Szenarien, desto besser ist das kollisionsvermeidende Verhalten des Roboters. Dabei ist es vor allem wichtig eine *Varianz* in den Daten zu haben (wie oben beschrieben) und nicht nur eine große Menge an Bildern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image)\n",
    "display(widgets.HBox([free_count, free_button]))\n",
    "display(widgets.HBox([blocked_count, blocked_button]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abschließend muss die Kameraverbindung wieder geschlossen werden, damit diese später in einem anderen NOtebook wieder genutzt werden kann."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wie geht es weiter?\n",
    "\n",
    "Wurden genügend DAten gesammelt, können diese auf einen Computer mit einer Leistungsstarken GPU kopiert werden. Dafür kann das folgende *Terminal* Kommando aufgerufen werden, um dataset Ordner in eine *zip*-Datei umzuwandeln.\n",
    "\n",
    "> Der ! Prefix gibt an, dass die Zelle als *shell* (oder *terminal*) Kommando ausgeführt werden soll.\n",
    "\n",
    "> Die -r Flag im zip Kommando indiziert *recursive*, dass alle untergeordneten Dateien mit berücksichtigt werden, die -q Flag indiziert *quiet*, damit das zip Kommando keine Ausgabe in das Terminal auslöst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!zip -r -q dataset.zip dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die ``dataset.zip`` Datei kann nun heruntergeladen und auf den Zielrechner kopiert werden.  You should download the zip file using the Jupyter Lab file browser by right clicking and selecting ``Download``.\n",
    "\n",
    "Im nächsten Schritt und gleichzeitig auch nächsten Notebook wird dann das neuronale Netz trainiert."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
